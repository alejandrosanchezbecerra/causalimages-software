#!/usr/bin/env Rscript
#' Perform causal estimation under image confounding
#'
#' @param obsW A numeric vector where `0`'s correspond to control units and `1`'s to treated units.
#' @param obsY A numeric vector containing observed outcomes.
#' @param imageKeysOfUnits A vector of length `length(obsY)` specifying the unique image ID associated with each unit. Samples of `imageKeysOfUnits` are fed into the package to call images into memory.
#' @param file Path to a tfrecord file generated by `WriteTfRecord`.
#' @param conda_env A `conda` environment where computational environment lives, usually created via `causalimages::BuildBackend()`. Default = `"CausalImagesEnv"`.
#' @param conda_env_required A Boolean stating whether use of the specified conda environment is required.
#' @param X An optional numeric matrix containing tabular information used if `orthogonalize = T`. `X` is normalized internally and salience maps with respect to `X` are transformed back to the original scale.
#' @param long,lat Optional vectors specifying longitude and latitude coordinates for units. Used only for describing highest and lowest probability neighorhood units if specified.
#' @param transportabilityMat Optional matrix with a column named `imageKeysOfUnits` specifying keys to be used by the package for generating treatment effect predictions for out-of-sample points.
#' @param figuresTag A string specifying an identifier that is appended to all figure names.
#' @param figuresPath A string specifying file path for saved figures made in the analysis.
#' @param plotBands An integer or vector specifying which band position (from the image representation) should be plotted in the visual results. If a vector, `plotBands` should have 3 (and only 3) dimensions (corresponding to the 3 dimensions to be used in RBG plotting).
#' @param nSGD Number of stochastic gradient descent (SGD) iterations. Default = `400L`
#' @param nBoot Number of bootstrap iterations for uncertainty estimation.
#' @param batchSize Batch size used in SGD optimization. Default = `50L`.
#' @param useTrainingPertubations Boolean specifying whether to randomly the image axes during training to reduce overfitting.
#' @param optimizeImageRep Boolean specifying whether to optimize over the image model representation (or only over downstream parameters).
#' @param dropoutRate Droppout rate used in training used to prevent overfitting (`dropoutRate = 0` corresponds to no dropout).
#' @param testFrac Default = `0.1`. Fraction of observations held out as a test set to evaluate out-of-sample loss values.
#' @param strides (default = `2L`) Integer specifying the strides used in the convolutional layers.
#' @param plotResults (default = `T`) Should analysis results be plotted?
#' @param dataType (default = `"image"`) String specifying whether to assume `"image"` or `"video"` data types.
#' @param nWidth_ImageRep Integer specifying width of image model representation.
#' @param nDepth_ImageRep Integer specifying depth of image model representation.
#' @param nWidth_Dense Integer specifying width of image model representation.
#' @param nDepth_Dense Integer specifying depth of dense model representation.
#' @param kernelSize Dimensions used in spatial convolutions.
#' @param temporalKernelSize Dimensions used in temporal convolutions (if `dataType = "video"``)
#' @param TfRecords_BufferScaler The buffer size used in `tfrecords` mode is `batchSize*TfRecords_BufferScaler`. Lower `TfRecords_BufferScaler` towards 1 if out-of-memory problems.
#'
#' @return Returns a list consisting of
#' \itemize{
#'   \item `ATE_est` ATE estimate.
#'   \item `ATE_se` Standard error estimate for the ATE.
#'   \item `plotResults` If set to `TRUE`, causal salience plots are saved to disk, characterizing the image confounding structure. See references for details.
#' }
#'
#' @section References:
#' \itemize{
#' \item  Connor T. Jerzak, Fredrik Johansson, Adel Daoud. Integrating Earth Observation Data into Causal Inference: Challenges and Opportunities. *ArXiv Preprint*, 2023.
#' }
#'
#' @examples
#' # For a tutorial, see
#' # github.com/cjerzak/causalimages-software/
#'
#' @export
#' @md

AnalyzeImageConfounding <- function(
                                   obsW,
                                   obsY,
                                   X = NULL,
                                   file = NULL,
                                   imageKeysOfUnits = NULL,
                                   nBoot = 50L,
                                   inputAvePoolingSize = 1L,
                                   useTrainingPertubations = T,

                                   orthogonalize = F,
                                   transportabilityMat = NULL,
                                   lat = NULL,
                                   long = NULL,
                                   conda_env = "CausalImagesEnv",
                                   conda_env_required = T,

                                   figuresTag = NULL,
                                   figuresPath = "./",
                                   plotBands = 1L,
                                   plotResults = T,

                                   optimizeImageRep = T,
                                   nWidth_ImageRep = 64L,  nDepth_ImageRep = 1L,
                                   nWidth_Dense = 32L,  nDepth_Dense = 1L,

                                   strides = 2L,
                                   dropoutRate = 0.1,
                                   batchSize = 50L,
                                   kernelSize = 3L,
                                   temporalKernelSize = 2L,
                                   nSGD  = 400L,
                                   testFrac = 0.05,
                                   TfRecords_BufferScaler = 4L,
                                   LEARNING_RATE_BASE = 0.005,
                                   dataType = "image",
                                   atError = "stop", # stop or debug
                                   seed = NULL){
  {
    print2("Establishing connection to computational environment (build via causalimages::BuildBackend())")
    library(tensorflow); if(!is.null(conda_env)){
      try(reticulate::use_condaenv(conda_env, required = conda_env_required),T)
    }
    Sys.sleep(.5); try(tf$square(1.),T); Sys.sleep(.5)
    # note: for balanced training, generate two tf records

    jax <<- reticulate::import("jax")
    np <<- reticulate::import("numpy")
    jnp <<- reticulate::import("jax.numpy")
    jmp <<- reticulate::import("jmp")
    optax <<- reticulate::import("optax")
    eq <<- reticulate::import("equinox")
    (py_gc <<- reticulate::import("gc"))$collect(); gc();

    image_dtype_tf <- tf$float16
    image_dtype <- jnp$float16
    if(is.null(seed)){seed <- ai(runif(1,1,10000))}
  }

  if(!optimizeImageRep & nDepth_ImageRep > 1){
    if(atError == "stop"){ stop("Stopping: When optimizeImageRep = T, nDepth_ImageRep must be 1L") }
    if(atError == "debug"){ browser() }
  }
  FigNameAppend <- sprintf("KW%s_InputAvePool%s_OptimizeImageRep%s_Tag%s",
                           kernelSize, inputAvePoolingSize,
                           optimizeImageRep, figuresTag)
  tagInFigures <- !is.null(figuresTag)
  figuresTag < ifelse(is.null(figuresTag), yes = "", no = figuresTag)

  # make all directory logic explicit
  loss_vec <- NULL
  orig_wd <- getwd()
  if( (cond1 <- substr(figuresPath, start = 0, stop = 1) == ".")  ){
    figuresPath <- gsub(figuresPath, pattern = '\\.', replacement = orig_wd)
  }
  if(!dir.exists(figuresPath)){ dir.create(figuresPath) }

  if(is.null(imageKeysOfUnits) & !is.null(imageKeysOfUnits)){ imageKeysOfUnits <- keys }
  if(batchSize > length(obsW)){ batchSize <- round(length(obsW) * 0.90) }

  if(!is.null(X)){ if(!"matrix" %in% class(X)){
    print2("Coercing X to matrix class..."); X <- as.matrix(  X )
  } }

  if(!is.null(X)){ if(is.na(sum(X))){ stop("Error: is.na(sum(X)) is TRUE; check for NAs or that all variables are numeric.") }}
  if(!is.null(X)){ if(any(apply(X,2,sd) == 0)){ stop("Error: any(apply(X,2,sd) == 0) is TRUE; a column in X seems to have no variance; drop column!") }}
  if(!is.null(X)){
      X <- t( (t(X) - (X_mean <- colMeans(X)) ) / (0.00001+(X_sd <- apply(X,2,sd))) )
  }
   if( XisNull <- is.null(X) ){ X <- as.matrix( rnorm(length(obsW), sd = 0.01 ) ) }

  {
    if(is.null(file)){stop("No file specified for tfrecord!")}
    changed_wd <- F; if(  !is.null(  file  )  ){
      print2("Establishing connection with tfrecord")
      tf_record_name <- file
      if( !grepl(tf_record_name, pattern = "/") ){
        tf_record_name <- paste("./",tf_record_name, sep = "")
      }
      tf_record_name <- strsplit(tf_record_name,split="/")[[1]]
      new_wd <- paste(tf_record_name[-length(tf_record_name)], collapse = "/")
      print2( sprintf("Temporarily re-setting the wd to %s", new_wd ) )
      changed_wd <- T; setwd( new_wd )
      tf_dataset <- tf$data$TFRecordDataset(  tf_record_name[length(tf_record_name)] )

      # helper functions
      useVideo <- dataType == "video"
      getParsed_tf_dataset_inference <- function(tf_dataset){
        dataset <- tf_dataset$map( function(x){parse_tfr_element(x, readVideo = useVideo, image_dtype = image_dtype_tf)} )
        return( dataset <- dataset$batch( ai(max(2L,round(batchSize/2L)  ))) )
      }
      getParsed_tf_dataset_train <- function(tf_dataset){
        dataset <- tf_dataset$map( function(x){parse_tfr_element(x, readVideo = useVideo, image_dtype = image_dtype_tf)} )
                                   #num_parallel_calls = tf$data$AUTOTUNE)
        dataset <- dataset$shuffle(buffer_size = tf$constant(ai(TfRecords_BufferScaler*batchSize),dtype=tf$int64),
                                   reshuffle_each_iteration = T)
        dataset <- dataset$batch(  ai(batchSize)   )
        #dataset <- dataset$prefetch(tf$data$AUTOTUNE)
        return( dataset  )
      }

      # setup iterators
      tf_dataset_train <- getParsed_tf_dataset_train( tf_dataset$skip(test_size <-  as.integer(round(testFrac * length(unique(imageKeysOfUnits)) ))) )$`repeat`(  -1L )
      tf_dataset_inference <- getParsed_tf_dataset_inference( tf_dataset )

      # reset iterators
      ds_iterator_train <- reticulate::as_iterator( tf_dataset_train )
      ds_iterator_inference <- reticulate::as_iterator( tf_dataset_inference )
    }

    if(useTrainingPertubations){
      trainingPertubations <- function(im_, key){
         AB <- ifelse(dataType == "video", yes = 1L, no = 0L)
         which_path <- jnp$squeeze(jax$random$categorical(key = key, logits = jnp$array(t(rep(0, times = 4)))),0L)# generates random # from 0L to 3L
         im_ <- jax$lax$cond(jnp$equal(which_path,jnp$array(0L)), true_fun = function(){ jnp$flip(im_, AB+1L) } , false_fun = function(){im_})
         im_ <- jax$lax$cond(jnp$equal(which_path,jnp$array(1L)), true_fun = function(){ jnp$flip(im_, AB+2L) }, false_fun = function(){im_})
         im_ <- jax$lax$cond(jnp$equal(which_path,jnp$array(2L)), true_fun = function(){ jnp$flip(jnp$flip(im_, AB+1L),AB+2L) }, false_fun = function(){im_})
          return( im_ )
      }
    }

    binaryCrossLoss <- function(W,prW){ return( - mean( log(prW+0.001)*W + log(1-prW+0.001)*(1-W) ) ) }
    InitImageProcessFn <- jax$jit(function(im, key, inference){
        # expand dims if needed
        if(length(imageKeysOfUnits) == 1){ im <- jnp$expand_dims(im,0L) }

        # normalize
        im <- jnp$divide(jnp$subtract(im, NORM_MEAN_array), NORM_SD_array)

        # training pertubations
        im <- jax$lax$cond(inference, true_fun = function(){ im }, false_fun = function(){ trainingPertubations(im, key) } )

        # downshift resolution if desired
        if(inputAvePoolingSize > 1){ im <- jax$vmap(function(im){ AvePoolingDownshift(im)}, 0L) }
        return( im  )
    })

    # some hyperparameters parameters
    figuresPath <- paste(strsplit(figuresPath,split="/")[[1]],collapse = "/")

    # get first iter batch for initializations
    print2("Calibrating first moments for input data normalization...")
    NORM_SD <- NORM_MEAN <- c(); for(momentCalIter in 1:(momentCalIters<-10)){
      ds_next_train <- ds_iterator_train$`next`()

      # setup normalizations
      ApplyAxis <- ifelse(dataType == "video", yes = 5, no = 4)
      if(is.null(NORM_MEAN)){ NORM_MEAN <- NORM_SD <- apply(as.array(ds_next_train[[1]]),ApplyAxis,sd); NORM_MEAN[] <- NORM_SD[] <- 0 }

      # update normalizations
      NORM_SD <- NORM_SD + apply(as.array(ds_next_train[[1]]),ApplyAxis,sd) / momentCalIters
      NORM_MEAN <- NORM_MEAN + apply(as.array(ds_next_train[[1]]),ApplyAxis,mean) / momentCalIters
    }
    NORM_MEAN_array <- jnp$array(array(NORM_MEAN,dim=c(1,1,1,length(NORM_MEAN))),image_dtype)
    NORM_SD_array <- jnp$array(array(NORM_SD,dim=c(1,1,1,length(NORM_SD))),image_dtype)
    if(dataType == "video"){
      NORM_MEAN_array <- jnp$expand_dims(NORM_MEAN_array, 0L)
      NORM_SD_array <- jnp$expand_dims(NORM_SD_array, 0L)
    }
    py_gc$collect()

    # define image downshift for supplementary analyses
    AvePoolingDownshift <- eq$nn$AvgPool2d(kernel_size = c(inputAvePoolingSize,inputAvePoolingSize), stride = c(inputAvePoolingSize,inputAvePoolingSize))

    # set up holders
    prW_est <- rep(NA,times = length(obsW))

    sigmoid <- function(.){1/(1+exp(-.))}
    tauHat_propensity_vec <- tauHat_propensityHajek_vec <- rep(NA,times = nBoot+1)
    if(!optimizeImageRep){
      # define train/test indices
      testIndices <- sample(1:length(obsY), max(2,length(obsY)*testFrac))
      trainIndices <- (1:length(obsY))[! 1:length(obsY) %in% testIndices]

      myGlmnet_coefs_mat <- matrix(NA, nrow = nBoot+1, ncol = nWidth_ImageRep + 1 + ifelse(!is.null(X), yes = ncol(X), no = 0))
      for(jr in 1L:(nBoot+1L)){
        print2( sprintf("Bootstrap iteration %s of %s", jr-1L, nBoot) )
        if(jr != (nBoot+1L)){ indices_ <- sample(1:length( imageKeysOfUnits ), length( imageKeysOfUnits ), replace = T) }
        if(jr == (nBoot+1L)){ indices_ <- 1:length( imageKeysOfUnits ) }

        # note: MyEmbeds_ are indexed by the original data ordering, resampling happens later
        {
          setwd(orig_wd); ImageRepresentations <- GetImageRepresentations(
            file = file,
            dataType = dataType,
            InitImageProcess = function(im){InitImageProcessFn(im,jax$random$PRNGKey(2L), T)},
            nWidth_ImageRep = nWidth_ImageRep,
            nDepth_ImageRep = nDepth_ImageRep,
            strides = strides,
            batchSize = batchSize,
            temporalKernelSize = temporalKernelSize,
            kernelSize = kernelSize,
            TfRecords_BufferScaler = 3L,
            imageKeysOfUnits = unique(imageKeysOfUnits), getRepresentations = T,
            returnContents = T,
            bn_momentum = 0.9,
            bn_epsilon = BN_EP,
            seed = ai(400L + jr)  ); setwd(new_wd)
          ImageRepresentations_df <- as.data.frame(  ImageRepresentations$ImageRepresentations )
          row.names(ImageRepresentations_df) <- as.character(unique(imageKeysOfUnits))
          ImageRepresentations_df <- ImageRepresentations_df[as.character(imageKeysOfUnits),]
        }
        # subset indices for training
        indices_forTraining <- indices_[indices_ %in% trainIndices]
        glmnetInput <- ifelse(XisNull, yes = list(ImageRepresentations_df),
                                       no = list(cbind(as.matrix(X), ImageRepresentations_df)))[[1]]
        myGlmnet_ <- glmnet::cv.glmnet(
          x = as.matrix(glmnetInput[indices_forTraining,]),
          y = as.matrix(obsW[indices_forTraining]),
          alpha = 0, # alpha = 0 is the ridge penalty
          family = "binomial")
        obsW_ <- obsW[indices_]
        obsY_ <- obsY[indices_]

        # compute QOIs
        myGlmnet_coefs_ <- as.matrix( glmnet::coef.glmnet(myGlmnet_, s = "lambda.min") )
        prW_est_ <- sigmoid( as.matrix(cbind(1, glmnetInput)) %*% myGlmnet_coefs_ )
        tauHat_propensity_vec[jr] <- tauHat_propensity_ <- mean(  obsW_*obsY_/c(prW_est_) - (1-obsW_)*obsY_/c(1-prW_est_) )
        tauHat_propensityHajek_vec[jr] <- tauHat_propensityHajek_ <- sum(  obsY_*prop.table(obsW_/c(prW_est_))) -
                        sum(obsY*prop.table((1-obsW_)/c(1-prW_est_) ))
        myGlmnet_coefs_mat[jr,] <- c(myGlmnet_coefs_)
        if(jr == (nBoot+1L)){
          nTrainable <- length(  myGlmnet_coefs_  )
          tauHat_propensityHajek <- tauHat_propensityHajek_
          tauHat_propensity <- tauHat_propensity_
          myGlmnet_coefs <- myGlmnet_coefs_
          prW_est <- prW_est_
          getTreatProb_batch <- function( ModelList, ModelList_fixed,
                                          m, x, vseed,
                                          StateList, seed, MPList, inference){
            ImageReps <- ImageRepArm_batch_R(ModelList_fixed, m, StateList, MPList, inference)
            if(!XisNull){
              x_m <- jnp$concatenate(list( jnp$ones(list(m$shape[[1]],1L)), x, ImageReps[[1]] ), 1L)
            }
            if(XisNull){
              x_m <- jnp$concatenate(list( jnp$ones(list(m$shape[[1]],1L)), ImageReps[[1]] ), 1L)
            }
            my_probs <- jax$nn$sigmoid(  jnp$matmul(x_m, LE( ModelList, "myGlmnet_coefs_tf" ) )  )
            return( list(my_probs, StateList) )
          }
          ModelList <- list("myGlmnet_coefs_tf" = jnp$array(myGlmnet_coefs, dtype = jnp$float32))
          ModelList_fixed <- ImageRepresentations[["ImageModel_And_State_And_MPPolicy_List"]][[1]]
          StateList <- ImageRepresentations[["ImageModel_And_State_And_MPPolicy_List"]][[2]]
          MPList <- ImageRepresentations[["ImageModel_And_State_And_MPPolicy_List"]][[3]]
          ImageRepArm_batch_R <- ImageRepresentations$ImageRepArm_batch_R
          ImageRepArm_batch <- ImageRepresentations$ImageRepArm_batch
        }
      }
    }

    if(optimizeImageRep){
      setwd(orig_wd); ImageRepresentations <- GetImageRepresentations(
        file = file,
        dataType = dataType,
        InitImageProcess = function(im){InitImageProcessFn(im,jax$random$PRNGKey(2L), T)},
        nWidth_ImageRep = nWidth_ImageRep,
        nDepth_ImageRep = nDepth_ImageRep,
        strides = strides,
        batchSize = batchSize,
        temporalKernelSize = temporalKernelSize,
        kernelSize = kernelSize,
        TfRecords_BufferScaler = 3L,
        imageKeysOfUnits = (UsedKeys <- sample(unique(imageKeysOfUnits),min(c(length(unique(imageKeysOfUnits)),2*batchSize)))), getRepresentations = T,
        returnContents = T,
        bn_momentum = 0.9,
        bn_epsilon = BN_EP,
        seed = ai(4003L)  ); setwd(new_wd)
        ImageModel_And_State_And_MPPolicy_List <- ImageRepresentations[["ImageModel_And_State_And_MPPolicy_List"]]
        ImageRepArm_OneObs <- ImageRepresentations[["ImageRepArm_OneObs"]]
        ImageRepArm_batch_R <- ImageRepresentations[["ImageRepArm_batch_R"]]
        rm( ImageRepresentations )

        batch_axis_name <- "batch"
        DenseList <- DenseStateList <- replicate(nDepth_Dense, list())
        for(d_ in 1L:nDepth_Dense){
          DenseProj_d <- eq$nn$Linear(in_features = ind_ <- ifelse(d_ == 1, yes = (nWidth_ImageRep + ifelse(XisNull, no = ncol(X), yes = 0L)),
                                                                            no =  nWidth_Dense),
                                             out_features = outd_ <- ifelse(d_ == nDepth_Dense,
                                                                            yes = 1L,
                                                                            no = nWidth_Dense),
                                             use_bias = T, key = jax$random$PRNGKey(d_+44L))
          LayerBN_d  <- eq$nn$BatchNorm(
                input_size = outd_, axis_name = batch_axis_name,
                momentum = 0.9, eps = 0.001, channelwise_affine = T)
          DenseStateList[[d_]] <- eval(parse(text = sprintf("list('BNState_d%s' = eq$nn$State( LayerBN_d ))", d_)))
          DenseList[[d_]] <- eval(parse(text = sprintf('list("DenseProj_d%s" = DenseProj_d,
                                                              "BN_%s" = LayerBN_d
                                                              )', d_, d_ )))
        }

        # ModelList <- DenseList; StateList <- DenseStateList
        GetDenseNet <- function(ModelList, ModelList_fixed, m, x,
                                vseed, StateList, seed, MPList, inference, type){
          m <- jnp$concatenate(list(m,x))

          for(d__ in 1:nDepth_Dense){
            m <-  LE(ModelList, sprintf("DenseProj_d%s",d__))(  m  )

            # BN + non-linearity
            if(d__ < nDepth_Dense){
              m <- LE(ModelList, sprintf("BN_d%s", d__))(m, state = StateList[[d__]], inference = inference)
              StateIndex <- LE_index(StateList, sprintf("BNState_d%s", d__))
              StateIndex <- paste(sapply(StateIndex, function(zer){ paste("[[", zer, "]]") }), collapse = "")
              eval(parse(text = sprintf("StateList%s <- m[[2]]", StateIndex)))
              m <- m[[1]]

              # Non-linearity
              m <- jax$nn$swish(  m   )
            }
          }
          return( list(m, StateList)  )
        }
        GetDense_batch <- jax$vmap(  function(
                  ModelList, ModelList_fixed, m, x, vseed, StateList, seed, MPList, inference){
                  GetDenseNet(ModelList, ModelList_fixed, m, x, vseed, StateList, seed, MPList, inference, type = '%s')
                },
                in_axes = list(NULL, NULL, 0L, 0L, 0L, NULL, NULL, NULL, NULL),
                   axis_name = batch_axis_name,
                   out_axes = list(0L, NULL) )
        getTreatProb_batch <- function( ModelList, ModelList_fixed,
                                        m, x, vseed,
                                        StateList, seed, MPList, inference){
          m <- ImageRepArm_batch_R(ModelList, m, StateList, MPList, inference)
          StateList <- m[[2]]; m <- m[[1]]
          m <- GetDense_batch(ModelList, ModelList_fixed, m, x, vseed, StateList, seed, MPList, inference)
          StateList <- m[[2]]; m <- m[[1]]
          m <- jax$nn$sigmoid( m )
          return( list(m, StateList) )
        }

        GetLoss <- function( ModelList, ModelList_fixed,
                            m, x, treat, vseed,
                            StateList, seed, MPList, inference){
          treatProb <- getTreatProb_batch( ModelList, ModelList_fixed,
                              m, x, vseed,
                              StateList, seed, MPList, inference )
          StateList <- treatProb[[2]]; treatProb <- jnp$squeeze( treatProb[[1]] )

          # label smoothing to prevent underflow (log(0) generates NAs)
          treatProb <- jnp$add(jnp$multiply(jnp$subtract(1., ep_LabelSmooth <- jnp$array(0.01)),treatProb),
                                      jnp$divide(ep_LabelSmooth, 2.))

          # compute negative log-likelihood loss
          NegLL <- jnp$mean( jnp$negative(  jnp$add( jnp$multiply(treat, jnp$log(treatProb)),
                                           jnp$multiply(1-treat, jnp$log(1-treatProb)) )) )
          print2("Returning loss + state...")
          NegLL <- MPList[[1]]$cast_to_output( NegLL ) # compute to output dtype
          NegLL <- MPList[[2]]$scale( NegLL ) # scale loss
          return( list(NegLL, StateList)  )
        }
        GradAndLossAndAux <-  eq$filter_jit( eq$filter_value_and_grad( GetLoss, has_aux = T) )

        # define final lists
        ModelList <- list(ImageModel_And_State_And_MPPolicy_List[[1]], DenseList)
        StateList <- list(ImageModel_And_State_And_MPPolicy_List[[2]], DenseStateList)
        ModelList_fixed <- jnp$array(0.)
        MPList <- list(jmp$Policy(compute_dtype="float16", param_dtype="float32", output_dtype="float16"),
                       jmp$DynamicLossScale(loss_scale = jnp$array(2^15,dtype = jnp$float16),
                                            min_loss_scale = jnp$array(1.,dtype = jnp$float16),
                                            period = 20L))
        ModelList <- MPList[[1]]$cast_to_param( ModelList )
        ModelList_fixed <- MPList[[1]]$cast_to_param( ModelList_fixed )
        rm( ImageModel_And_State_And_MPPolicy_List, DenseStateList, DenseList )

        # define optimizer and training step
        {
          unitwise_norm <- function(x){
            # """Computes norms of each output unit separately."""
            if(jnp$squeeze(x)$ndim <= 1L){  # Scalars and vectors
              squared_norm <- jnp$sum(jnp$square(x), keepdims=T)
            }
            # Note that this assumes parameters with a shape of length 3 are multihead
            # linear parameters--if you wish to apply AGC to 1D convs, you may need
            # to modify this line.
            if( x$ndim %in% c(2L, 3L)){  # Linear layers of shape IO or multihead linear
              squared_norm <- jnp$sum(jnp$square(x), axis=0L, keepdims=T)
            }

            # Conv kernels of shape HWIO - from original code
            # if( x$ndim == 4L){  squared_norm = jnp$sum(jnp$square(x), axis=c(0L, 1L, 2L), keepdims=T) }

            # Conv kernels of shape OIHW
            if( x$ndim == 4L){ squared_norm <- jnp$sum(jnp$square(x), axis=c(1L:3L), keepdims=T) }

            if( x$ndim == 5L){
              squared_norm <- jnp$sum(jnp$square(x), axis=c(1L:4L), keepdims=T)
            }

            return( jnp$broadcast_to(jnp$sqrt(squared_norm), x$shape) )
          }
          MyAdaptiveGradClip <- eq$filter_jit( function(updates, params){
            eps <- jnp$array(0.01); clipping <- jnp$array( 0.1 )
            g_norm <- jax$tree_util$tree_map(unitwise_norm, list(updates, params))
            p_norm <- g_norm[[2]]; g_norm <- g_norm[[1]]

            # Maximum allowable norm.
            max_norm = jax$tree_util$tree_map( function( x ){ clipping * jnp$maximum(x, eps)}, p_norm)

            # If grad norm > clipping * param_norm, rescale.
            updates <- jax$tree_util$tree_map(function(g_norm, max_norm, grad){
              clipped_grad <- grad * (max_norm / jnp$maximum(g_norm, jnp$array(0.001)))
              return( jnp$where(g_norm < max_norm, grad, clipped_grad))},
              g_norm, max_norm, updates)
            return( updates )
          } )
          LR_schedule <- optax$cosine_decay_schedule( init_value = LEARNING_RATE_BASE, decay_steps = nSGD )
          optax_optimizer <-  optax$chain(
            optax$clip(1), # optax$zero_nans(),
            # optax$adaptive_grad_clip(clipping = 0.1), # bug with equinox's Conv4D
            optax$adabelief( learning_rate = LR_schedule, eps=1e-8, eps_root=1e-8, b1 = 0.90, b2 = 0.999)
          )

          # model partition, setup state, perform parameter count
          ModelParams <- eq$partition(ModelList, eq$is_array)[[1]]
          ModelOther <-  eq$partition(ModelList, eq$is_array)[[2]]
          opt_state <- optax_optimizer$init(  ModelParams)
          print2(sprintf("Total trainable parameter count: %s", nTrainable <- sum(unlist(lapply(jax$tree_leaves(ModelParams), function(zer){zer$size})))))

          # jit update fxns
          jit_apply_updates <- eq$filter_jit(optax$apply_updates)
          jit_get_update <- eq$filter_jit(optax_optimizer$update)
        }

        print2("Starting training...")
        keys2indices_list <- tapply(1:length(imageKeysOfUnits), imageKeysOfUnits, c)
        L2grad_vec <- loss_vec <- rep(NA,times=(nSGD))
        keysUsedInTraining <- c()
        n_sgd_iters <- nSGD; tauMeans <- c();i_<-1L ; DoneUpdates <- 0L; for(i in i_:nSGD){
          if(i %% 5 == 0 | i == 1){gc(); py_gc$collect()}

          ds_next_train <- ds_iterator_train$`next`()

          # if we run out of observations, reset iterator
          RestartedIterator <- F; if( is.null(ds_next_train) ){
              gc(); py_gc$collect()
              print2("Re-setting iterator! (type 1)")
              ds_iterator_train <- reticulate::as_iterator( tf_dataset_train )
              ds_next_train <-  ds_iterator_train$`next`(); gc();py_gc$collect()
          }

          # get a new batch if size mismatch - size mismatches generate new cached compiled fxns
          if(!RestartedIterator){
              if(dim(ds_next_train[[1]])[1] != batchSize){
                print2("Re-setting iterator! (type 2)")
                ds_iterator_train <- reticulate::as_iterator( tf_dataset_train )
                ds_next_train <-  ds_iterator_train$`next`(); gc(); py_gc$collect()
              }
          }

          # select batch indices based on keys
          batch_keys <- unlist(  lapply( ds_next_train[[3]]$numpy(), as.character) )
          batch_indices <- sapply(batch_keys,function(key_){ f2n( sample(as.character( keys2indices_list[[key_]] ), 1) ) })
          ds_next_train <- ds_next_train[[1]]
          if(any(!batch_indices %in% keysUsedInTraining)){ keysUsedInTraining <- c(keysUsedInTraining, batch_keys[!batch_keys %in% keysUsedInTraining]) }

          # training step
          if(T == F){
            m <- InitImageProcessFn(jnp$array(ds_next_train),  jax$random$PRNGKey(600L+i), inference = F)
            x <- jnp$array(X[batch_indices,],dtype = jnp$float16)
            treat <- jnp$array(obsW[batch_indices],dtype = jnp$float16)
            vseed <- jax$random$split(jax$random$PRNGKey( 500L+i ),batchSize)
            seed <- jax$random$PRNGKey( 123L+i ) ; inference <- F
          }
          # rm(GradAndLossAndAux); GradAndLossAndAux <-  eq$filter_jit( eq$filter_value_and_grad( GetLoss, has_aux = T) )
          v_and_grad_loss_jax <- try(GradAndLossAndAux(
            MPList[[1]]$cast_to_compute(ModelList), MPList[[1]]$cast_to_compute(ModelList_fixed),
            InitImageProcessFn(jnp$array(ds_next_train),  jax$random$PRNGKey(600L+i), inference = F), # m
            jnp$array(X[batch_indices,],dtype = jnp$float16), # x
            jnp$array(obsW[batch_indices],dtype = jnp$float16), # treat
            jax$random$split(jax$random$PRNGKey( 500L+i ),batchSize),  # vseed
            StateList, # StateList
            jax$random$PRNGKey( 123L+i ), # seed
            MPList, # MPlist
            F), T) # inference
          if(!"try-error" %in% class(v_and_grad_loss_jax)){
            # get updated state
            StateList_tmp <- v_and_grad_loss_jax[[1]][[2]] # state

            # get loss + grad
            loss_vec[i] <- myLoss_forGrad <- np$array( MPList[[2]]$unscale( v_and_grad_loss_jax[[1]][[1]] ) )# value
            myGrad_jax <- v_and_grad_loss_jax[[2]] # grads
            myGrad_jax <- eq$partition(myGrad_jax, eq$is_inexact_array)
            myGrad_jax_aux <- myGrad_jax[[2]]; myGrad_jax <- myGrad_jax[[1]]

            # unscale + adjust loss scale is some non-finite or NA
            if(i == 1){
              Map2Zero <- eq$filter_jit(function(input){
                jax$tree_map(function(x){ jnp$where(jnp$isnan(x), jnp$array(0), x)}, input) })
              AllFinite <- jax$jit( jmp$all_finite )
            }
            myGrad_jax <- Map2Zero( MPList[[2]]$unscale( myGrad_jax ) )
            AllFinite <- jmp$all_finite( myGrad_jax )
            MPList[[2]] <- MPList[[2]]$adjust( AllFinite  )
            # which(is.na( c(unlist(lapply(jax$tree_leaves(myGrad_jax), function(zer){np$array(zer)}))) ) )
            # which(is.infinite( c(unlist(lapply(jax$tree_leaves(myGrad_jax), function(zer){np$array(zer)}))) ) )

            # update parameters if finite gradients
            DoUpdate <- !is.na(myLoss_forGrad) & np$array(AllFinite) & !is.infinite(myLoss_forGrad)
            if(! DoUpdate ){ print2("Warning: Not updating parameters due to non-finite gradients...") }
            if( DoUpdate ){
              DoneUpdates <- DoneUpdates + 1
              if(DoneUpdates == 1){
                CostAnalysis <- GradAndLossAndAux$lower(
                  MPList[[1]]$cast_to_compute(ModelList), MPList[[1]]$cast_to_compute(ModelList_fixed),
                  InitImageProcessFn(jnp$array(ds_next_train),  jax$random$PRNGKey(600L+i), inference = F), # m
                  jnp$array(X[batch_indices,],dtype = jnp$float16), # x
                  jnp$array(obsW[batch_indices],dtype = jnp$float16), # treat
                  jax$random$split(jax$random$PRNGKey( 500L+i ),batchSize),  # vseed
                  StateList, # StateList
                  jax$random$PRNGKey( 123L+i ), # seed
                  MPList, # MPlist
                  F ) # inference
                CostAnalysis <- CostAnalysis$lowered$cost_analysis()
                TotalFlops <- CostAnalysis$flops
                try(print2( sprintf("log(FLOPS): %.3f",log(TotalFlops, base = 10) )),T)
              }

              # get updates
              myGrad_jax <- MPList[[1]]$cast_to_param( myGrad_jax )
              myGrad_jax <- MyAdaptiveGradClip( myGrad_jax, ModelParams )
              updates_and_opt_state <- jit_get_update( updates = myGrad_jax,
                                                       state = opt_state,
                                                       params = ModelParams)

              # separate updates from state
              optax_updates <- eq$combine(updates_and_opt_state[[1]], myGrad_jax_aux)
              opt_state <- updates_and_opt_state[[2]]

              # perform update
              ModelParams_GlobalPartitioned <- GlobalPartition(ModelParams,PartFxn)
              ModelParams_GlobalPartitioned[[1]] <- jit_apply_updates(
                params = ModelParams_GlobalPartitioned[[1]],
                updates = GlobalPartition(optax_updates,PartFxn)[[1]])

              # setup updates
              NULLS_MAT <- rrapply::rrapply(ModelParams_GlobalPartitioned[[1]],f = function(zer){
                cond_ <- try(is.null(zer),T)
                if( "try-error" %in% class(cond_)){cond_<-T}
                if(!cond_){ret_<-F};if(cond_){ret_ <- T};
                return(ret_) },how="list")
              NULLS_MAT <- (NULLS_MAT <- LinearizeNestedList(NULLS_MAT,NameSep = "]][["))[unlist(NULLS_MAT)]
              for(entry_ in names(NULLS_MAT)){
                eval(parse(text = sprintf(
                  "ModelParams_GlobalPartitioned[[1]]%s <- ModelParams_GlobalPartitioned[[2]]%s",
                  (entry_ <- paste("[[",entry_,"]]",sep="")), entry_)))
              }
              ModelParams <- ModelParams_GlobalPartitioned[[1]]

              # feed in updates for state and model
              ModelList <- eq$combine( ModelParams, ModelOther )
              StateList <- StateList_tmp
              rm(ModelParams_GlobalPartitioned, StateList_tmp)
            }
          }

          # print diagnostics
          i_ <- i ; if(i %% 10 == 0 | i < 10 ){
            print2(sprintf("SGD iteration %s of %s - Loss: %.2f (%.1f%%)",
                           i, n_sgd_iters, loss_vec[i], 100*mean(loss_vec[i] <= loss_vec[1:i],na.rm=T)))
            loss_vec <- f2n(loss_vec); loss_vec[is.infinite(loss_vec)] <- NA
            try(plot(rank(na.omit(loss_vec)), cex.main = 0.95,ylab = "Loss Function Rank",xlab="SGD Iteration Number"), T)
            if(i > 10){ try_ <- try(points(smooth.spline( rank(na.omit(loss_vec) )), col="red",type = "l",lwd=5),T) }
          }
        } # end for(i in i_:nSGD){
        print2("Getting predicted quantities...")
        GetSummaries <- eq$filter_jit(jax$vmap( function(ModelList, ModelList_fixed,
                                               m, x, vseed,
                                               StateList, seed, MPList){
          # image representation model
          m <- ImageRepArm_batch_R(ModelList, m, StateList, MPList, T)
          StateList <- m[[2]] ; m <- m[[1]]
          m <- GetDense_batch(ModelList, ModelList_fixed, m, x, vseed, StateList, seed, MPList, T)
          StateList <- m[[2]]; m <- m[[1]]
          m <- jax$nn$sigmoid( m )
          return( list('ProbW' = m) )
        }, in_axes = list(NULL, NULL,
                          NULL, 0L, NULL,
                          NULL, NULL, NULL ) ) )

        inference_counter <- 0; nUniqueKeys <- length( unique(imageKeysOfUnits) )
        #KeyQuantCuts <- gtools::quantcut(1:nUniqueKeys, q = ceiling( nUniqueKeys / (batchSize*0.33) ))
        KeyQuantCuts <- 1L:nUniqueKeys
        passedIterator <- NULL; Results_by_keys <- replicate(length(unique(KeyQuantCuts)),list());
        usedKeys <- c()
        for(cut_ in unique(KeyQuantCuts)){ # use when not incorporating X's
          # cut_ <- unique(KeyQuantCuts)[1]
          inference_counter <- inference_counter + 1
          zer <- which(cut_  ==  KeyQuantCuts)
          #gc(); py_gc$collect()
          atP <- max(zer)/nUniqueKeys
          if( any(zer %% 10 == 0) | 1 %in% zer ){ print2(sprintf("Proportion done: %.3f", atP)) }
          {
            setwd(orig_wd); ds_next_in <- GetElementFromTfRecordAtIndices(
                                                uniqueKeyIndices = which(unique(imageKeysOfUnits) %in% unique(imageKeysOfUnits)[zer]),
                                                filename = file,
                                                iterator = passedIterator,
                                                readVideo = useVideo,
                                                image_dtype = image_dtype_tf,
                                                nObs = length(unique(imageKeysOfUnits)),
                                                return_iterator = T ); setwd(new_wd)
            passedIterator <- ds_next_in[[2]]
            key_ <- unlist(  lapply( list(ds_next_in[[1]][[3]]$numpy() ), as.character) )
            ds_next_in <-  jnp$array( ds_next_in[[1]][[1]] )

            # deal with batch 1 case here
            if(length(ds_next_in$shape) == 3 & dataType == "image"){ ds_next_in <- jnp$expand_dims(ds_next_in, 0L) }
            if(length(ds_next_in$shape) == 4 & dataType == "video"){ ds_next_in <- jnp$expand_dims(ds_next_in, 0L) }
          }

          # get summaries and save
          usedKeys <- c(usedKeys, key_)
          obs_with_key <- which(imageKeysOfUnits %in% key_)
          x <- jnp$expand_dims(jnp$array(  ifelse(length(obs_with_key) == 1, yes = list(t(X[obs_with_key,])),
                                                              no = list(X[obs_with_key,]))[[1]],
                           dtype = jnp$float16), 0L)$transpose( c(1L, 0L, 2L) )
          GottenSummaries <- GetSummaries(ModelList, ModelList_fixed,
                                          InitImageProcessFn(jnp$array(ds_next_in),  jax$random$PRNGKey(600L+i), inference = T),
                                          x,
                                          jax$random$split(jax$random$PRNGKey(as.integer(runif(1,0, 10000))), ds_next_in$shape[[1]]),
                                          StateList, jax$random$PRNGKey(as.integer(runif(1,0,100000))), MPList)
          ret_list <- list("ProbW" = as.matrix(np$array(GottenSummaries[[1]])[,,1]),
                           "obsIndex" = as.matrix(obs_with_key),
                           "key" = as.matrix( rep(key_, length(obs_with_key)) ))
          Results_by_keys[[inference_counter]] <- ret_list
        }
        Results_by_keys_list <- Results_by_keys
        Results_by_keys <- ( do.call(rbind, Results_by_keys_list) )
        Results_by_keys <- apply(Results_by_keys,2,function(zer){(do.call(rbind,zer))})
        Results_by_keys <- as.data.frame( Results_by_keys )
        prW_est <- f2n(  Results_by_keys$ProbW )

        # checks
        # usedKeys  == unique(imageKeysOfUnits)
        # unlist(Results_by_keys[["key"]]) == unique(imageKeysOfUnits)
        # mean(unlist(Results_by_keys[["key"]]) %in% imageKeysOfUnits)
        # mean(imageKeysOfUnits %in% unlist(  Results_by_keys[["key"]] ))
        trainIndices <- which( imageKeysOfUnits %in% keysUsedInTraining )
        testIndices <- which( !imageKeysOfUnits %in% keysUsedInTraining )
        tauHat_propensityHajek <- sum(  obsY*prop.table(obsW/c(prW_est))) - sum(obsY*prop.table((1-obsW)/c(1-prW_est) ))
        tauHat_propensityHajek_vec <- replicate(nBoot, { i_ <- sample(1:length(obsW),length(obsW), T)
                        sum(  obsY[i_]*prop.table(obsW[i_]/c(prW_est[i_]))) -
                          sum(obsY[i_]*prop.table((1-obsW)[i_]/(1-prW_est)[i_] )) } )
    }

    # process in and out of sample losses
    prWEst_baseline <- prW_est
    prWEst_baseline[] <- mean( obsW[trainIndices] )
    lossCE_OUT_baseline <- binaryCrossLoss(obsW[testIndices], prWEst_baseline[testIndices])
    lossCE_IN_baseline <- binaryCrossLoss(obsW[trainIndices], prWEst_baseline[trainIndices])
    lossCE_OUT <-  binaryCrossLoss(  obsW[testIndices], prW_est[testIndices]  )
    lossCE_IN <-  binaryCrossLoss(  obsW[trainIndices], prW_est[trainIndices]  )
    lossClassError_OUT_baseline <- 1/length(testIndices) * (sum( prWEst_baseline[testIndices][ obsW[testIndices] == 1] < 0.5) +
                           sum( prWEst_baseline[testIndices][ obsW[testIndices] == 0] > 0.5))
    lossClassError_IN_baseline <- 1/length(trainIndices) * (sum( prWEst_baseline[trainIndices][ obsW[trainIndices] == 1] < 0.5) +
                                                              sum( prWEst_baseline[trainIndices][ obsW[trainIndices] == 0] > 0.5))
    lossClassError_OUT <- 1/length(testIndices) * (sum( prW_est[testIndices][ obsW[testIndices] == 1] < 0.5) +
                           sum( prW_est[testIndices][ obsW[testIndices] == 0] > 0.5))
    lossClassError_IN <- 1/length(trainIndices) * (sum( prW_est[trainIndices][ obsW[trainIndices] == 1] < 0.5) +
                                                     sum( prW_est[trainIndices][ obsW[trainIndices] == 0] > 0.5))
    ModelEvaluationMetrics <- list(
      "CELoss_out" = lossCE_OUT,
      "CELoss_out_baseline" = lossCE_OUT_baseline,
      "CELoss_in" = lossCE_IN,
      "CELoss_in_baseline" = lossCE_IN_baseline,
      "ClassError_out" = lossClassError_OUT,
      "ClassError_out_baseline" = lossClassError_OUT_baseline,
      "ClassError_in" = lossClassError_IN,
      "ClassError_in_baseline" = lossClassError_IN_baseline
    )

    # reset to original wd which was altered during records initialization
    # do this before plotting to avoid disrupting plot save locations
    if( changed_wd ){ setwd(  orig_wd  ) }

    # do some analysis with examples
    processedDims <- NULL; if( plotResults ){
      print2("Plotting the image confounding results...")
      indices_t <- (1:length(obsW))[which(obsW==1)]
      indices_c <- (1:length(obsW))[which(obsW==0)]

      showPerGroup <- min(c(3,unlist(table(obsW))), na.rm = T)
      top_control <- ordered_control <- indices_c[order_c <- order(prW_est[indices_c],decreasing = F)]
      top_treated <- ordered_treated <- indices_t[order_t <- order(prW_est[indices_t],decreasing = T)]

      # drop duplicates
      if(!is.null(long)){
        longLat_t <- paste(round(long[indices_t[order_t]],5L),
                                round(lat[indices_t[order_t]],5L),sep="_")
        longLat_c <- paste(round(long[indices_c[order_c]],5L),
                                round(lat[indices_c[order_c]],5L),sep="_")
        top_treated <- ordered_treated[!duplicated(longLat_t)]
        top_control <- ordered_control[!duplicated(longLat_c)]
      }
      plot_indices <- c( top_control <- top_control[1:showPerGroup],
                         top_treated <- top_treated[1:showPerGroup] )

      for(pos_ in 2L:3L){
        dLogProb_d <- jax$grad(function(ModelList, ModelList_fixed,
                                        m, x, vseed,
                                        StateList, seed, MPList){
                    ModelList <- MPList[[1]]$cast_to_param( ModelList )
                    ModelList_fixed <- MPList[[1]]$cast_to_param( ModelList_fixed )
                    StateList <- MPList[[1]]$cast_to_param( StateList )
                    m <- MPList[[1]]$cast_to_param( m ); x <- MPList[[1]]$cast_to_param( x )
                    m <- jax$device_put(m, jax$devices('cpu')[[1]])
                    out_ <-  getTreatProb_batch(ModelList, ModelList_fixed,
                                           m, x, vseed,
                                           StateList, seed, MPList, T)[[1]]  # scaling for non-zero gradients
                    out_ <- jnp$log(out_ / (1-out_))
                    return(  jnp$squeeze(out_)  ) }, pos_)
        if(pos_ == 2L){ dLogProb_dImage <- dLogProb_d }
        if(pos_ == 3L){ dLogProb_dX <- dLogProb_d }
      }
      ImGrad_fxn <- eq$filter_jit( function(ModelList, ModelList_fixed,
                                            m, x, vseed,
                                            StateList, seed, MPList){
        # cast to float32
        ModelList <- MPList[[1]]$cast_to_param( ModelList )
        ModelList_fixed <- MPList[[1]]$cast_to_param( ModelList_fixed )
        StateList <- MPList[[1]]$cast_to_param( StateList )
        m <- MPList[[1]]$cast_to_param( m ); x <- MPList[[1]]$cast_to_param( x )
        m <- jax$device_put(m, jax$devices('cpu')[[1]])
        ImageGrad_o <- jnp$squeeze(dLogProb_dImage(ModelList, ModelList_fixed,
                                       m, x, vseed, StateList, seed, MPList), 0L)
        reduceDim <- ifelse( dataType == "video", yes = 3L, no = 2L)
        ImageGrad_L2 <- jnp$linalg$norm(ImageGrad_o+0.000001, axis = reduceDim, keepdims = T)
        ImageGrad_mean <- jnp$mean(ImageGrad_o, axis = reduceDim, keepdims = T)
        return( list(ImageGrad_L2,  # salience magnitude
                     ImageGrad_mean) ) # salience direction
      }, device = jax$devices('cpu')[[1]])
      MPList <- list(jmp$Policy(compute_dtype="float32", param_dtype="float32", output_dtype="float32"),
           jmp$DynamicLossScale(jnp$array(2^15), period = 1000L))
      makePlots <- function(){
        salience_try <- try({
        print2("Plotting salience maps...")
        nrows_im <- 2
        pdf(sprintf("%s/CSM_%s.pdf", figuresPath, FigNameAppend),
            width = length(plot_indices)*5+2,height = nrows_im*5)
        {
          layout(matrix(1:(nrows_im*(1+length(plot_indices))),
                        ncol = 1+length(plot_indices)),
                 width = c(0.5,rep(5,length(plot_indices))),
                 height = rep(5,times=nrows_im)); in_counter <- 0
          for(text_ in c("Raw Image","Salience Map")){
            if(dataType == "image"){
              par(mar=c(0,0,0,0)); plot(0, main = "", ylab = "",cex = 0,
                   xlab = "", ylim = c(0,1), xlim = c(0,1),
                   xaxt = "n",yaxt = "n",bty = "n")
              text(0.5,0.5,labels = text_, srt=90,cex=3)
            }
          plot_index_counter <- 0; for(in_ in plot_indices){
            print(c(text_, in_))
            gc(); py_gc$collect()
            plot_index_counter <- plot_index_counter + 1

            # get data
            setwd(orig_wd); ds_next_in <- GetElementFromTfRecordAtIndices(
                                                    uniqueKeyIndices = which(unique(imageKeysOfUnits) %in% imageKeysOfUnits[in_]),
                                                    filename = file,
                                                    readVideo = useVideo,
                                                    nObs = length(imageKeysOfUnits) ); setwd(new_wd)
            ds_next_in[[1]] <- jnp$array( ds_next_in[[1]] )
            if(length(ds_next_in[[1]]$shape) == 3 & dataType == "image"){ ds_next_in[[1]] <- jnp$expand_dims(ds_next_in[[1]], 0L) }
            if(length(ds_next_in[[1]]$shape) == 4 & dataType == "video"){ ds_next_in[[1]] <- jnp$expand_dims(ds_next_in[[1]], 0L) }

            col_ <- ifelse(in_ %in% top_treated, yes = "black", no = "gray")
            in_counter <- in_counter + 1
            if(  !is.null(lat)  ){ long_lat_in_ <- sprintf("Lat-Lon: %.3f, %.3f", f2n(lat[in_]), f2n(long[in_])) }

            im_orig <- im_ <- InitImageProcessFn( im = jnp$array(ds_next_in[[1]]), key = jax$random$PRNGKey(3L), inference = T )
            XToConcat_values <- jnp$array(t(X[in_,]),jnp$float16)
            im_ <- np$array(jnp$squeeze(im_,c(0L)))

            # calculate salience map using log probabilities
            # m <- jmp$cast_to_full(im_orig); x <- jmp$cast_to_full(XToConcat_values); seed <- jax$random$PRNGKey(10L); vseed <- jnp$expand_dims(seed,0L)
            salience_map <- np$array(  ImGrad_fxn(
                                        jmp$cast_to_full(ModelList), jmp$cast_to_full(ModelList_fixed),
                                        jmp$cast_to_full(im_orig),
                                        jmp$cast_to_full(XToConcat_values),
                                        jnp$expand_dims(jax$random$PRNGKey(10L),0L),
                                        StateList, jax$random$PRNGKey(10L), MPList )[[1]] )
            if(dataType == "image"){ salience_map <- salience_map[,,1] }
            if(dataType == "video"){ salience_map <- salience_map[,,,1] }

            # do plotting
            orig_scale_im_ <- sapply(1:length(NORM_MEAN), function(band_){
                                       if(dataType == "image"){
                                         im_[,,band_] <- 0.1+im_[,,band_]*NORM_SD[band_] + NORM_MEAN[band_]
                                         return( im_[,,band_] )
                                       }
                                       if(dataType == "video"){
                                         im_[,,,band_] <- 0.1+im_[,,,band_]*NORM_SD[band_] + NORM_MEAN[band_]
                                         return( im_[,,,band_] )
                                       }  }, simplify="array")

            # plot results
            par(mar = (mar_vec <- c(2,1,3,1)))
            if(dataType == "image"){
              plotRBG <- !(length(plotBands) < 3 | dim(orig_scale_im_)[length(dim(orig_scale_im_))] < 3)
              if(!plotRBG){
                causalimages::image2(
                  as.matrix( orig_scale_im_[,,plotBands[1]] ),
                  main = long_lat_in_, cex.main = 2.5, col.main =  col_,
                  xlab = ifelse( plot_index_counter == 1,
                                 yes = ifelse(tagInFigures, yes = figuresTag, no = ""),
                                 no = "")
                )
              }
              if(plotRBG){
                 plot(0, main = long_lat_in_, col.main = col_,
                      ylab = "", xlab = "",
                      cex.main = 4, ylim = c(0,1), xlim = c(0,1),
                      cex = 0, xaxt = "n",yaxt = "n",bty = "n")
                 mtext(side = 1, ifelse( plot_index_counter == 1,
                               yes = ifelse(tagInFigures, yes = figuresTag, no = ""),
                               no = ""), cex = 1)
                 orig_scale_im_raster <- raster::brick(orig_scale_im_[,,plotBands[1:3]])
                 try_ <- try(raster::plotRGB(orig_scale_im_raster, r = 1, g = 2, b = 3,
                                 add = T, main = long_lat_in_, stretch = "lin"), T)
                 if("try-error" %in% class(try_)){
                   try_ <- try(raster::plotRGB(orig_scale_im_raster, r = 1, g = 2, b = 3,
                                               add = T, main = long_lat_in_), T)
                 }
              }

              # plot salience map
              par(mar = mar_vec)
              try_salience <- try({salience_map[salience_map>0] <- salience_map[salience_map>0] / (0.001+sd(salience_map[salience_map>0]))},T)
              if("try-error" %in% class(try_salience)){ browser() }
              salience_map <- sign(salience_map)*log(abs(salience_map)+1)
              image2( salience_map, xlab = ifelse(tagInFigures, yes = imageKeysOfUnits[in_], no = ""),cex.lab = 1)
              par(mar = mar_vec)
            }
            if(dataType == "video"){
              # plot raw image
              nTimeSteps <- dim(salience_map)[1]
              animation::saveGIF({
              for (t_ in 1:nTimeSteps) {
              plotRBG <- !(length(plotBands) < 3 | dim(orig_scale_im_)[length(dim(orig_scale_im_))] < 3)
              if(!plotRBG){
                causalimages::image2(
                  as.matrix( orig_scale_im_[t_,,,plotBands[1]] ),
                  main = long_lat_in_, cex.main = 2.5, col.main =  col_,
                  xlab = ifelse( plot_index_counter == 1,
                                 yes = ifelse(tagInFigures, yes = figuresTag, no = ""),
                                 no = "")
                )
              }
              if(plotRBG){
                plot(0, main = long_lat_in_, col.main = col_,
                     ylab = "", xlab = "",
                     cex.main = 4, ylim = c(0,1), xlim = c(0,1),
                     cex = 0, xaxt = "n",yaxt = "n",bty = "n")
                mtext(side = 1, ifelse( plot_index_counter == 1,
                                        yes = ifelse(tagInFigures, yes = figuresTag, no = ""),
                                        no = ""), cex = 1)
                orig_scale_im_raster <- raster::brick(orig_scale_im_[t_,,,plotBands[1:3]])
                try_ <- try(raster::plotRGB(orig_scale_im_raster, r = 1, g = 2, b = 3,
                                            add = T, main = long_lat_in_, stretch = "lin"), T)
                if("try-error" %in% class(try_)){
                  try_ <- try(raster::plotRGB(orig_scale_im_raster, r = 1, g = 2, b = 3,
                                              add = T, main = long_lat_in_), T)
                }
              }
              }},
              movie.name = sprintf("%s/CSM_%s_%s.gif", figuresPath, FigNameAppend, plot_index_counter),
              autobrowse = F, autoplay = F)

              # plot salience map
              par(mar = mar_vec)
              animation::saveGIF({
                for (t_ in 1:nTimeSteps) {
                salience_map[salience_map>0] <- salience_map[salience_map>0] / (0.001+sd(salience_map[salience_map>0]))
                salience_map <- sign(salience_map)*log(abs(salience_map)+1)
                image2( salience_map[t_,,], xlab = ifelse(tagInFigures, yes = imageKeysOfUnits[in_], no = ""),cex.lab = 1)
                }}, movie.name = sprintf("%s/SalienceMap_%s_%s.gif", figuresPath, FigNameAppend, plot_index_counter), autobrowse = F, autoplay = F)
              par(mar = mar_vec)
          }
        }
          }
        }
        eval(parse(text = ifelse(dataType == "image", yes = "dev.off()", no = "NULL") ))
        },T)
        if('try-error' %in% class(salience_try)){
          print(salience_try);
          if(atError == "stop"){ stop("Problem in salience map computation!")  }
          if(atError == "debug"){ browser() }
        }

        if(optimizeImageRep){
          pdf(sprintf("%s/Loss_%s.pdf", figuresPath,FigNameAppend))
            par(mar = c(5,5,1,1))
            try(plot(loss_vec, cex = 1.5, cex.lab = 2,
                     xlab = "Iteration",
                     ylab = "Loss"),T);
            try(points(smooth.spline(na.omit(loss_vec)),type="l",lwd=3),T)
          dev.off()
        }

        try({
        print2("Plotting propensity histogram...")
        pdf(sprintf("%s/Hist_%s.pdf", figuresPath, FigNameAppend))
        {
          par(mfrow=c(1,1))
          d0 <- density(prW_est[obsW==0])
          d1 <- density(prW_est[obsW==1])
          plot(d1,lwd=2,xlim = c(-0.1,1.1),ylim =c(0,max(c(d1$y,d0$y),na.rm=T)*1.2),
               cex.axis = 1.2,ylab = "",xaxt = "n",
               xlab = ifelse(tagInFigures, yes = figuresTag, no = ""),
               main = "Density Plots for \n Estimated Pr(T=1 | Confounders)",cex.main = 2)
          axis(1, at = seq(0,1,by = 0.25))
          points(d0,lwd=2,type = "l",col="gray",lty=2)
          text(d0$x[which.max(d0$y)[1]],
               max(d0$y,na.rm=T)*1.1,label = "T = 0",col="gray",cex=2)
          text(d1$x[which.max(d1$y)[1]],
               max(d1$y,na.rm=T)*1.1,label = "T = 1",col="black",cex=2)
        }
        dev.off()
        }, T)
      }
      makePlots()
    }

    # compute salience for tabular covariates
    SalienceX_se <- SalienceX <- NULL; if(!XisNull){
    if( optimizeImageRep ){
        SalienceX <- c(); samp_counter <- 0
        for(keyNum_ in sample(1:length(unique(imageKeysOfUnits)), 25, replace = T)){
          samp_counter <- samp_counter + 1
          if(samp_counter %% 5 == 0){  print2(sprintf("Tabular Salience Iteration %s of %s", samp_counter, 25)) }
          sampIndex_ <- which(imageKeysOfUnits %in% unique(imageKeysOfUnits)[keyNum_])[1]

          # extract data
          setwd(orig_wd); ds_next_in <- GetElementFromTfRecordAtIndices(
                                                           uniqueKeyIndices = keyNum_,
                                                           filename = file,
                                                           readVideo = useVideo,
                                                           nObs = length(unique(imageKeysOfUnits) ) ); setwd(new_wd)
          ds_next_in[[1]] <- jnp$array(ds_next_in[[1]])
          if(length(ds_next_in[[1]]$shape) == 3 & dataType == "image"){ ds_next_in[[1]] <- jnp$expand_dims(ds_next_in[[1]], 0L) }
          if(length(ds_next_in[[1]]$shape) == 4 & dataType == "video"){ ds_next_in[[1]] <- jnp$expand_dims(ds_next_in[[1]], 0L) }

          im_ <- InitImageProcessFn( jnp$array(ds_next_in[[1]]), jax$random$PRNGKey(432L), T)
          x_ <- jnp$array(t(X[sampIndex_,]), jnp$float16)
          # m <- jmp$cast_to_full(im_); x <- jmp$cast_to_full(x_); vseed <- seed <- jax$random$PRNGKey(10L)
          SalienceX_contrib <- np$array(  dLogProb_dX(  ModelList, ModelList_fixed,
                        jmp$cast_to_full(im_),
                        jmp$cast_to_full(x_),
                        jax$random$split(jax$random$PRNGKey( 500L+i ),x_$shape[[1]]),
                        StateList, jax$random$PRNGKey(10L), MPList ) )
          SalienceX <- rbind(SalienceX, SalienceX_contrib)
        }
        SalienceX <- colMeans( SalienceX ); names( SalienceX ) <- colnames(X)
        SalienceX <- SalienceX*X_sd  +  X_mean
      }
    if(!optimizeImageRep){
        SalienceX <- myGlmnet_coefs[-1][1:ncol(X)] # drop intercept, then extract variables of interest
        SalienceX_se <- apply(myGlmnet_coefs_mat, 2, sd)[-1][1:ncol(X)]
        if(!is.null(SalienceX)){ names(SalienceX_se) <- colnames(X) }
        SalienceX <- SalienceX*X_sd  +  X_mean
    } }
    # rescale the salience map into original scale

    postDiffInLat <- preDiffInLat <- NULL
    if(!is.null(lat)){
      preDiffInLat <- colMeans(cbind(long[obsW == 1],lat[obsW == 1])) -
        colMeans(cbind(long[obsW == 0],lat[obsW == 0]))
      postDiffInLat <- colSums(cbind(long[obsW == 1],lat[obsW == 1])*prop.table(1/prW_est[obsW == 1])) -
        colSums(cbind(long[obsW == 0],lat[obsW == 0])*prop.table(1/(1-prW_est[obsW == 0])))
    }

    # set salience map names
    if(!is.null(SalienceX)){ names(SalienceX) <- colnames(X) }

    print2( "Done with image confounding analysis!" ); try(setwd(orig_wd), T)
    return(    list(
      "tauHat_propensityHajek"  = tauHat_propensityHajek,
      "tauHat_propensityHajek_se"  = sd(tauHat_propensityHajek_vec,na.rm=T),
      "tauHat_diffInMeans"  = mean(obsY[which(obsW==1)],na.rm=T) - mean(obsY[which(obsW==0)],na.rm=T),
      "tauHat_diffInMeans_se"  = c(sqrt(se(obsY[which(obsW==1)])^2 + se(obsY[which(obsW==0)])^2)),
      "SalienceX" = SalienceX,
      "SalienceX_se" = SalienceX_se,
      "prW_est" = prW_est,
      "SGD_loss_vec" = loss_vec,
      "LatitudeAnalysis" = list("preDiffInLat" = preDiffInLat, "postDiffInLat"  = postDiffInLat),
      "ModelEvaluationMetrics" = ModelEvaluationMetrics,
      "nTrainableParameters" = nTrainable
    ) )
  }
}
